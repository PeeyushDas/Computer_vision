{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397716f1",
   "metadata": {},
   "source": [
    "<h1> Assignment-5 </h1>\n",
    "<h2>Name:- Peeyush Das Roll:-122CS0071</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4981b",
   "metadata": {},
   "source": [
    "1. Implement deep multilayer perceptron (MLP) models with the following specifications using TensorFlow for classifying the MNIST dataset. Train the model on the MNIST training set and evaluate its performance on the test set. Write modularized code and call it 10 times and compute the mean of test accuracy for each of the following 4 Sequential models.\n",
    "\n",
    "a. Model-1: 4 hidden layers having 128, 64, 32, 16 number of neurons respectively with activation function sigmoid, tanh, relu and selu respectively and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as SGD with batch size set to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49c68e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples : 60000 and each image is of shape (28, 28)\n",
      "Number of testing examples : 10000 and each image is of shape (28, 28)\n",
      "Number of training examples : 60000 and each image is of shape (784)\n",
      "Number of test examples : 10000 and each image is of shape (784)\n",
      "Class label of first image : 5\n",
      "Class label of first image in vector form is:  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "    \n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d, %d)\"%(X_train.shape[1], X_train.shape[2]))\n",
    "print(\"Number of testing examples :\", X_test.shape[0], \"and each image is of shape (%d, %d)\"%(X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
    "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d)\"%(X_train.shape[1]))\n",
    "print(\"Number of test examples :\", X_test.shape[0], \"and each image is of shape (%d)\"%(X_test.shape[1]))\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "print(\"Class label of first image :\", y_train[0])\n",
    "\n",
    "\n",
    "Y_train = utils.to_categorical(y_train, 10) \n",
    "Y_test = utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"Class label of first image in vector form is: \",Y_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d888cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.1000 - loss: 2.6137 - val_accuracy: 0.1113 - val_loss: 2.2949\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1334 - loss: 2.4273 - val_accuracy: 0.1771 - val_loss: 2.2877\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1200 - loss: 2.3887 - val_accuracy: 0.1296 - val_loss: 2.2882\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1293 - loss: 2.3588 - val_accuracy: 0.1691 - val_loss: 2.2865\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0864 - loss: 2.3641 - val_accuracy: 0.1191 - val_loss: 2.2886\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0978 - loss: 2.3656 - val_accuracy: 0.1506 - val_loss: 2.2922\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1271 - loss: 2.3358 - val_accuracy: 0.1367 - val_loss: 2.2905\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1204 - loss: 2.3278 - val_accuracy: 0.1338 - val_loss: 2.2911\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1156 - loss: 2.3306 - val_accuracy: 0.1587 - val_loss: 2.2863\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.1367 - loss: 2.3175 - val_accuracy: 0.1678 - val_loss: 2.2857\n"
     ]
    }
   ],
   "source": [
    "output_dim = 10\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "batch_size = 32 \n",
    "nb_epoch = 10\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(128, input_dim=784))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Dense(64))\n",
    "model1.add(Activation('tanh'))\n",
    "model1.add(Dropout(0.4))\n",
    "\n",
    "model1.add(Dense(32))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "model1.add(Dense(16))\n",
    "model1.add(Activation('selu'))\n",
    "model1.add(Dropout(0.1))\n",
    "\n",
    "model1.add(Dense(10))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model1.fit(X_train, Y_train, steps_per_epoch=50,batch_size = 32, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab01de",
   "metadata": {},
   "source": [
    "b.\tModel-2: 4 hidden layers having 128, 64, 32, 16 number of neurons respectively with activation function sigmoid, tanh, relu and selu respectively and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as Adam with batch size set to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a95b6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.1768 - loss: 2.3844 - val_accuracy: 0.6385 - val_loss: 1.3291\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4451 - loss: 1.6109 - val_accuracy: 0.7489 - val_loss: 0.9030\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5456 - loss: 1.3451 - val_accuracy: 0.7745 - val_loss: 0.7600\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5983 - loss: 1.1811 - val_accuracy: 0.8217 - val_loss: 0.6279\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6477 - loss: 1.0836 - val_accuracy: 0.8289 - val_loss: 0.5858\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6564 - loss: 1.0105 - val_accuracy: 0.8403 - val_loss: 0.5509\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6644 - loss: 1.0005 - val_accuracy: 0.8599 - val_loss: 0.5020\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7033 - loss: 0.9247 - val_accuracy: 0.8641 - val_loss: 0.4772\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7083 - loss: 0.8872 - val_accuracy: 0.8657 - val_loss: 0.4723\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7371 - loss: 0.8402 - val_accuracy: 0.8610 - val_loss: 0.4732\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(128, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('tanh'))\n",
    "model2.add(Dropout(0.4))\n",
    "\n",
    "model2.add(Dense(32))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "model2.add(Dense(16))\n",
    "model2.add(Activation('selu'))\n",
    "model2.add(Dropout(0.1))\n",
    "\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model2.fit(X_train, Y_train, steps_per_epoch=50,batch_size = 32, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67424074",
   "metadata": {},
   "source": [
    "c.\tModel-3: 4 hidden layers having 128, 64, 32, 16 number of neurons respectively with activation function sigmoid, tanh, relu and selu respectively and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as AdamW with learning rate 0.1 with batch size set to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aeed532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.0980 - loss: 2.8664 - val_accuracy: 0.1028 - val_loss: 2.3266\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1013 - loss: 2.3266 - val_accuracy: 0.1010 - val_loss: 2.3148\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1107 - loss: 2.3263 - val_accuracy: 0.1135 - val_loss: 2.3489\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1076 - loss: 2.3260 - val_accuracy: 0.1135 - val_loss: 2.3623\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1003 - loss: 2.3331 - val_accuracy: 0.1032 - val_loss: 2.3157\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0844 - loss: 2.3272 - val_accuracy: 0.1135 - val_loss: 2.3353\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1045 - loss: 2.3336 - val_accuracy: 0.0982 - val_loss: 2.3487\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0994 - loss: 2.3299 - val_accuracy: 0.1010 - val_loss: 2.3285\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0803 - loss: 2.3338 - val_accuracy: 0.1010 - val_loss: 2.3475\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0943 - loss: 2.3380 - val_accuracy: 0.0892 - val_loss: 2.3166\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(128, input_dim=784))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Dense(64))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dropout(0.4))\n",
    "\n",
    "model3.add(Dense(32))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.3))\n",
    "\n",
    "model3.add(Dense(16))\n",
    "model3.add(Activation('selu'))\n",
    "model3.add(Dropout(0.1))\n",
    "\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "model3.compile(optimizer= AdamW(learning_rate = 0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model3.fit(X_train, Y_train, steps_per_epoch=50,batch_size = 32,  epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf9bca",
   "metadata": {},
   "source": [
    "d.\tModel-4: 4 hidden layers having 128, 64, 32, 16 number of neurons respectively with activation function sigmoid, tanh, relu and selu respectively and dropout rate set to 0.5, 0.4, 0.3, 0.1 respectively. Use optimizer as Nadam with a learning rate of 0.1 with batch size set to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5ecf79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.0851 - loss: 2.8363 - val_accuracy: 0.1010 - val_loss: 2.3299\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0975 - loss: 2.3226 - val_accuracy: 0.1135 - val_loss: 2.3080\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0962 - loss: 2.3193 - val_accuracy: 0.0974 - val_loss: 2.3106\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0953 - loss: 2.3182 - val_accuracy: 0.0974 - val_loss: 2.3356\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1071 - loss: 2.3265 - val_accuracy: 0.0980 - val_loss: 2.3423\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0936 - loss: 2.3333 - val_accuracy: 0.1028 - val_loss: 2.3300\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.1094 - loss: 2.3172 - val_accuracy: 0.1135 - val_loss: 2.3095\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1153 - loss: 2.3212 - val_accuracy: 0.0982 - val_loss: 2.3146\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1042 - loss: 2.3210 - val_accuracy: 0.1010 - val_loss: 2.3217\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0835 - loss: 2.3318 - val_accuracy: 0.1010 - val_loss: 2.3283\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(128, input_dim=784))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.add(Dropout(0.5))\n",
    "\n",
    "model4.add(Dense(64))\n",
    "model4.add(Activation('tanh'))\n",
    "model4.add(Dropout(0.4))\n",
    "\n",
    "model4.add(Dense(32))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Dense(16))\n",
    "model4.add(Activation('selu'))\n",
    "model4.add(Dropout(0.1))\n",
    "\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))\n",
    "\n",
    "model4.compile(optimizer=Nadam(learning_rate = 0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model4.fit(X_train, Y_train, steps_per_epoch=50, epochs=nb_epoch, batch_size = 32,  verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5c816d",
   "metadata": {},
   "source": [
    "2. Tune the hyperparameters using kerastuner to select the best learning rate among the set {0.1, 0.01, 0.15} with batch size varying between {4,8,16} and first hidden layer neurons varying between 250 to 260 with a step value of 2. 2nd, 3rd and 4th hidden layer contains 16, 8, 4 numbers of neurons respectively. The four layers have activation functions sigmoid, tanh, relu, and selu, respectively. Use optimizer as SGD and find the best hyperparameters to predict the MNIST test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da013c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db8d3c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperparam_tuning\\mnist_sgd_tuning\\tuner0.json\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2426 - loss: 1.9916 - val_accuracy: 0.5760 - val_loss: 1.0211\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 1.2428 - val_accuracy: 0.7314 - val_loss: 0.7716\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5914 - loss: 1.0912 - val_accuracy: 0.7754 - val_loss: 0.6753\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6433 - loss: 0.9935 - val_accuracy: 0.8288 - val_loss: 0.6044\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6680 - loss: 0.9333 - val_accuracy: 0.8407 - val_loss: 0.5513\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6928 - loss: 0.8821 - val_accuracy: 0.8618 - val_loss: 0.4798\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7074 - loss: 0.8385 - val_accuracy: 0.8912 - val_loss: 0.4643\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.8242 - val_accuracy: 0.8996 - val_loss: 0.4317\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.7778 - val_accuracy: 0.9143 - val_loss: 0.3827\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.7517 - val_accuracy: 0.9242 - val_loss: 0.3559\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.4089\n",
      "Test Accuracy: 0.9269\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  \n",
    "x_train, x_test = x_train.reshape(-1, 784), x_test.reshape(-1, 784)  \n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential([\n",
    "        Dense(hp.Int('units', 250, 260, step=2), input_shape=(784,)),\n",
    "        Activation('sigmoid'),\n",
    "        Dropout(hp.Float('dropout_1', 0.3, 0.6, step=0.1)),\n",
    "        Dense(16),\n",
    "        Activation('tanh'),\n",
    "        Dropout(hp.Float('dropout_2', 0.2, 0.5, step=0.1)),\n",
    "        Dense(8),\n",
    "        Activation('relu'),\n",
    "        Dropout(hp.Float('dropout_3', 0.1, 0.4, step=0.1)),\n",
    "        Dense(4),\n",
    "        Activation('selu'),\n",
    "        Dropout(hp.Float('dropout_4', 0.05, 0.2, step=0.05)),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    lr = hp.Choice('learning_rate', [0.1, 0.01, 0.15])\n",
    "    model.compile(\n",
    "        optimizer=SGD(learning_rate=lr),  \n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,  \n",
    "    objective='val_accuracy',\n",
    "    max_trials=1,\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='mnist_sgd_tuning'\n",
    ")\n",
    "tuner.search(x_train, y_train, epochs=2, validation_split=0.2, batch_size=8)\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e5e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
